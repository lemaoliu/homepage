## Seminars at LAT Group

## In 2020

| Date   |      Titiles      |  Speakers |
|----------|:-------------:|------:|
| 7-22 |  Pre-training via Paraphrasing <br /> Pretraining with Contrastive Sentence Objectives Improves Discourse Performance of Language Models  | Deng Cai 
| 7-22 |    MASS: Masked Sequence to Sequence Pre-training for Language Generation <br /> BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension <br />  PALM: Pre-training an Autoencoding&Autoregressive Language Model for Context-conditioned Generation  |   Zhangming Chan |


| 7-17 |  In Neural Machine Translation, What Does Transfer Learning Transfer? <br /> Demystifying Self-Supervised Learning: An Info-theoretic Framework.  | Guanlin Li 
| 7-17 |    A Joint Named-Entity Recognizer for Heterogeneous Tag-sets Using a Tag Hierarchy <br /> Distantly Supervised Named Entity Recognition using Positive-Unlabeled Learning  |   Honglin Han |


<!---
<table>
    <thead>
        <tr>
            <th>Layer 1</th>
            <th>Layer 2</th>
            <th>Layer 3</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td rowspan=4>L1 Name</td>
            <td rowspan=2>L2 Name A</td>
            <td>L3 Name A</td>
        </tr>
        <tr>
            <td>L3 Name B</td>
        </tr>
        <tr>
            <td rowspan=2>L2 Name B</td>
            <td>L3 Name C</td>
        </tr>
        <tr>
            <td>L3 Name D</td>
        </tr>
    </tbody>
</table>
--->
